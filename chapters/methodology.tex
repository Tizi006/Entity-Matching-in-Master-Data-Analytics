\section{Methodology}
Our methodology follows a comparative framework designed to 
evaluate three distinct interpretability paradigms: gradient-based 
attribution, local linear surrogates, and counterfactual 
perturbations. This section details our model architecture, 
data serialization, and the technical implementation of our 
explanation modules.

\subsection{Dataset and Input Serialization}
We utilize the structured \textbf{DBLP-ACM} benchmark dataset 
from the Magellan repository \cite{li2020ditto}. The dataset 
comprises bibliographic records with four attributes: 
\textit{Title}, \textit{Authors}, \textit{Venue}, and \textit{Year}.



To process these records with a Transformer architecture, we 
serialize each entity pair $(e_a, e_b)$ into a single sequence. 
Attributes are prefixed with their labels and concatenated using 
the \texttt{[SEP]} token:
\begin{center}
\small \texttt{[CLS] Title: A [SEP] Title: B ... [SEP]}
\end{center}
This format allows the model's self-attention mechanism to 
perform cross-attribute comparison directly within the hidden layers.

\subsection{Black-Box Model: Transformer-based EMModel}
Our primary matching engine is a custom PyTorch-based 
\textit{EMModel}. The architecture leverages the 
\textit{bert-base-uncased} backbone \cite{devlin2019bert} 
containing 12 layers and 110M parameters.



The model processes the serialized input and extracts the 
final hidden state of the \texttt{[CLS]} token, denoted 
as $h_{[CLS]} \in \mathbf{text}{R}^{768}$, which serves as the 
aggregate semantic representation of the record pair. This 
vector is passed through a linear dropout layer and a 
classification head:
\[ P(\text{match}) = \text{Softmax}(W \cdot h_{[CLS]} + b) \]
where $W$ and $b$ are the weights and biases of the final layer.

\subsection{Feature Attribution: Integrated Gradients}
We implement \textbf{Integrated Gradients (IG)} \cite{sundararajan2017axiomatic} 
via the \textbf{Captum} library \cite{kokhlikyan2020captum}. IG 
calculates the integral of gradients along a straight-line path 
from a baseline $x'$ to the input $x$. In our implementation, we 
apply IG directly to the word embedding layer. This produces 
continuous importance scores that satisfy the axioms of 
\textit{completeness} and \textit{sensitivity}, revealing which 
specific tokens drive the matching decision.

\subsection{Local Linear Surrogates: LEMON}
As a surrogate-based baseline, we employ \textbf{LEMON} \cite{Barlaug2023}, 
an adaptation of LIME optimized for Entity Matching. To address the 
limitations of standard perturbations in paired data, LEMON utilizes 
\textbf{dual explanations} to preserve cross-record context and 
introduces \textbf{attribution potential} to measure the sensitivity 
of missing features in non-match predictions.

\subsection{Counterfactuals: TextAttack Framework}
To provide actionable "what-if" insights, we generate 
counterfactual explanations by leveraging an adversarial 
search paradigm. Formally, a counterfactual describes the 
minimal modification required to change the model's 
classification for a specific record pair \cite{wachter2017}. 

\subsection{Comparative Objectives}
Our evaluation compares these methods based on:
\begin{itemize}
    \item \textbf{Fidelity:} The accuracy with which the explanation 
    represents the model's sensitivity.
    \item \textbf{Stability:} The consistency of the results 
    across similar record pairs.
    \item \textbf{Usability:} The clarity of the output for 
    human-in-the-loop validation.
\end{itemize}