\section{Conclusion}

This study benchmarks \textbf{LEMON}, \textbf{Integrated Gradients}, and 
\textbf{Counterfactuals} for Transformer-based Entity Matching. 
Evaluating these methods against our core objectives of \textit{fidelity}, 
\textit{stability}, and \textit{usability}, we demonstrate their distinct 
roles in explaining complex matching decisions in master data analytics.

\subsection{Comparative Findings}
\begin{itemize}
    \item \textbf{Fidelity:} \textbf{Integrated Gradients (IG)} achieved 
    superior numerical fidelity. By satisfying the Completeness Axiom through 
    an optimized \texttt{[MASK]} baseline, we reduced the convergence delta 
    to \textbf{0.50}, significantly outperforming the zero-vector baseline 
    ($\Delta \approx 1.91$). This ensures mathematical reliability even in 
    saturated probability regions, whereas \textbf{LEMON} required a 
    specialized \textit{attribution potential} metric to extract meaningful 
    signals from non-match predictions.
    
    \item \textbf{Stability:} Both methods demonstrated high stability through 
    different mechanisms. IG's path integration yielded a low attribution 
    standard deviation of \textbf{0.42}, effectively smoothing out gradient 
    noise. \textbf{LEMON} achieved stability by aggregating token-level 
    perturbations into coherent attribute features via its dual-explanation 
    strategy, albeit at a higher memory cost (requiring significant VRAM 
    for counterfactual granularity).
    
    \item \textbf{Usability:} \textbf{Counterfactuals} offered the most 
    actionable insights for human-in-the-loop validation. By restricting 
    perturbations to a \textbf{15\% span budget}, they isolated minimal 
    textual ``flips'' that are immediately understandable for data stewards. 
    In contrast, IG's aggregated visualizations provided a superior global 
    overview, correctly identifying systemic model biases---such as the 
    consistently low relevance of the \textit{Venue} attribute in attributions 
    (though it shows high sensitivity in perturbations, indicating potential 
    for flips).
\end{itemize}

\paragraph{Limitation on Runtime Analysis:} 
It should be noted that \textbf{computational efficiency} (runtime) was 
explicitly excluded from this comparative analysis. As the explanation 
modules were executed on heterogeneous hardware environments, a 
standardized, comparable measurement of inference speed was not feasible. 
Consequently, our evaluation focuses strictly on the qualitative 
dimensions of fidelity, stability, and usability.

\subsection{Model Behavior}
Our cross-method analysis confirms that the BERT-based model acts as a 
"text-first" matcher. All three explainers converged on the finding that 
\textit{Title} and \textit{Authors} serve as the primary anchors for 
decision-making, while numeric fields like \textit{Year} act largely as 
secondary filters. 

Since meaningful explanations often required analyzing comparative 
interactions rather than isolated attributes, we advocate for a 
\textbf{hybrid explanation pipeline}, particularly for ambiguous 
record pairs. In such a framework, \textbf{Integrated Gradients} 
serves as a tool for technical auditing and bias detection, while 
\textbf{Counterfactuals} provide the concrete evidence needed for 
operational data stewardship.